{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/300, score: 11, e: 1.0\n",
      "Best model saved - episode: 0.0, score: 11.0\n",
      "episode: 1/300, score: 10, e: 1.0\n",
      "episode: 2/300, score: 17, e: 0.92\n",
      "Best model saved - episode: 2.0, score: 17.0\n",
      "episode: 3/300, score: 19, e: 0.76\n",
      "Best model saved - episode: 3.0, score: 19.0\n",
      "episode: 4/300, score: 11, e: 0.68\n",
      "episode: 5/300, score: 12, e: 0.61\n",
      "episode: 6/300, score: 20, e: 0.49\n",
      "Best model saved - episode: 6.0, score: 20.0\n",
      "episode: 7/300, score: 15, e: 0.43\n",
      "episode: 8/300, score: 23, e: 0.34\n",
      "Best model saved - episode: 8.0, score: 23.0\n",
      "episode: 9/300, score: 12, e: 0.3\n",
      "episode: 10/300, score: 28, e: 0.23\n",
      "Best model saved - episode: 10.0, score: 28.0\n",
      "episode: 11/300, score: 22, e: 0.18\n",
      "episode: 12/300, score: 11, e: 0.16\n",
      "episode: 13/300, score: 16, e: 0.14\n",
      "episode: 14/300, score: 107, e: 0.047\n",
      "Best model saved - episode: 14.0, score: 107.0\n",
      "episode: 15/300, score: 124, e: 0.014\n",
      "Best model saved - episode: 15.0, score: 124.0\n",
      "episode: 16/300, score: 77, e: 0.0099\n",
      "episode: 17/300, score: 76, e: 0.0099\n",
      "episode: 18/300, score: 69, e: 0.0099\n",
      "episode: 19/300, score: 76, e: 0.0099\n",
      "episode: 20/300, score: 69, e: 0.0099\n",
      "episode: 21/300, score: 94, e: 0.0099\n",
      "episode: 22/300, score: 88, e: 0.0099\n",
      "episode: 23/300, score: 120, e: 0.0099\n",
      "episode: 24/300, score: 114, e: 0.0099\n",
      "episode: 25/300, score: 90, e: 0.0099\n",
      "episode: 26/300, score: 102, e: 0.0099\n",
      "episode: 27/300, score: 210, e: 0.0099\n",
      "Best model saved - episode: 27.0, score: 210.0\n",
      "episode: 28/300, score: 99, e: 0.0099\n",
      "episode: 29/300, score: 130, e: 0.0099\n",
      "episode: 30/300, score: 117, e: 0.0099\n",
      "episode: 31/300, score: 87, e: 0.0099\n",
      "episode: 32/300, score: 96, e: 0.0099\n",
      "episode: 33/300, score: 90, e: 0.0099\n",
      "episode: 34/300, score: 88, e: 0.0099\n",
      "episode: 35/300, score: 34, e: 0.0099\n",
      "episode: 36/300, score: 22, e: 0.0099\n",
      "episode: 37/300, score: 84, e: 0.0099\n",
      "episode: 38/300, score: 25, e: 0.0099\n",
      "episode: 39/300, score: 16, e: 0.0099\n",
      "episode: 40/300, score: 19, e: 0.0099\n",
      "episode: 41/300, score: 128, e: 0.0099\n",
      "episode: 42/300, score: 84, e: 0.0099\n",
      "episode: 43/300, score: 111, e: 0.0099\n",
      "episode: 44/300, score: 67, e: 0.0099\n",
      "episode: 45/300, score: 162, e: 0.0099\n",
      "episode: 46/300, score: 111, e: 0.0099\n",
      "episode: 47/300, score: 149, e: 0.0099\n",
      "episode: 48/300, score: 50, e: 0.0099\n",
      "episode: 49/300, score: 80, e: 0.0099\n",
      "episode: 50/300, score: 113, e: 0.0099\n",
      "episode: 51/300, score: 12, e: 0.0099\n",
      "episode: 52/300, score: 100, e: 0.0099\n",
      "episode: 53/300, score: 137, e: 0.0099\n",
      "episode: 54/300, score: 114, e: 0.0099\n",
      "episode: 55/300, score: 99, e: 0.0099\n",
      "episode: 56/300, score: 135, e: 0.0099\n",
      "episode: 57/300, score: 171, e: 0.0099\n",
      "episode: 58/300, score: 121, e: 0.0099\n",
      "episode: 59/300, score: 106, e: 0.0099\n",
      "episode: 60/300, score: 111, e: 0.0099\n",
      "episode: 61/300, score: 126, e: 0.0099\n",
      "episode: 62/300, score: 115, e: 0.0099\n",
      "episode: 63/300, score: 121, e: 0.0099\n",
      "episode: 64/300, score: 157, e: 0.0099\n",
      "episode: 65/300, score: 102, e: 0.0099\n",
      "episode: 66/300, score: 136, e: 0.0099\n",
      "episode: 67/300, score: 71, e: 0.0099\n",
      "episode: 68/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 68.0, score: 499.0\n",
      "episode: 69/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 69.0, score: 499.0\n",
      "episode: 70/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 70.0, score: 499.0\n",
      "episode: 71/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 71.0, score: 499.0\n",
      "episode: 72/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 72.0, score: 499.0\n",
      "episode: 73/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 73.0, score: 499.0\n",
      "episode: 74/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 74.0, score: 499.0\n",
      "episode: 75/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 75.0, score: 499.0\n",
      "episode: 76/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 76.0, score: 499.0\n",
      "episode: 77/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 77.0, score: 499.0\n",
      "episode: 78/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 78.0, score: 499.0\n",
      "episode: 79/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 79.0, score: 499.0\n",
      "episode: 80/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 80.0, score: 499.0\n",
      "episode: 81/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 81.0, score: 499.0\n",
      "episode: 82/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 82.0, score: 499.0\n",
      "episode: 83/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 83.0, score: 499.0\n",
      "episode: 84/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 84.0, score: 499.0\n",
      "episode: 85/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 85.0, score: 499.0\n",
      "episode: 86/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 86.0, score: 499.0\n",
      "episode: 87/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 87.0, score: 499.0\n",
      "episode: 88/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 88.0, score: 499.0\n",
      "episode: 89/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 89.0, score: 499.0\n",
      "episode: 90/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 90.0, score: 499.0\n",
      "episode: 91/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 91.0, score: 499.0\n",
      "episode: 92/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 92.0, score: 499.0\n",
      "episode: 93/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 93.0, score: 499.0\n",
      "episode: 94/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 94.0, score: 499.0\n",
      "episode: 95/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 95.0, score: 499.0\n",
      "episode: 96/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 96.0, score: 499.0\n",
      "episode: 97/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 97.0, score: 499.0\n",
      "episode: 98/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 98.0, score: 499.0\n",
      "episode: 99/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 99.0, score: 499.0\n",
      "episode: 100/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 100.0, score: 499.0\n",
      "episode: 101/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 101.0, score: 499.0\n",
      "episode: 102/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 102.0, score: 499.0\n",
      "episode: 103/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 103.0, score: 499.0\n",
      "episode: 104/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 104.0, score: 499.0\n",
      "episode: 105/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 105.0, score: 499.0\n",
      "episode: 106/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 106.0, score: 499.0\n",
      "episode: 107/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 107.0, score: 499.0\n",
      "episode: 108/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 108.0, score: 499.0\n",
      "episode: 109/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 109.0, score: 499.0\n",
      "episode: 110/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 110.0, score: 499.0\n",
      "episode: 111/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 111.0, score: 499.0\n",
      "episode: 112/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 112.0, score: 499.0\n",
      "episode: 113/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 113.0, score: 499.0\n",
      "episode: 114/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 114.0, score: 499.0\n",
      "episode: 115/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 115.0, score: 499.0\n",
      "episode: 116/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 116.0, score: 499.0\n",
      "episode: 117/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 117.0, score: 499.0\n",
      "episode: 118/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 118.0, score: 499.0\n",
      "episode: 119/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 119.0, score: 499.0\n",
      "episode: 120/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 120.0, score: 499.0\n",
      "episode: 121/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 121.0, score: 499.0\n",
      "episode: 122/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 122.0, score: 499.0\n",
      "episode: 123/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 123.0, score: 499.0\n",
      "episode: 124/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 124.0, score: 499.0\n",
      "episode: 125/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 125.0, score: 499.0\n",
      "episode: 126/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 126.0, score: 499.0\n",
      "episode: 127/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 127.0, score: 499.0\n",
      "episode: 128/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 128.0, score: 499.0\n",
      "episode: 129/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 129.0, score: 499.0\n",
      "episode: 130/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 130.0, score: 499.0\n",
      "episode: 131/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 131.0, score: 499.0\n",
      "episode: 132/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 132.0, score: 499.0\n",
      "episode: 133/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 133.0, score: 499.0\n",
      "episode: 134/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 134.0, score: 499.0\n",
      "episode: 135/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 135.0, score: 499.0\n",
      "episode: 136/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 136.0, score: 499.0\n",
      "episode: 137/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 137.0, score: 499.0\n",
      "episode: 138/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 138.0, score: 499.0\n",
      "episode: 139/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 139.0, score: 499.0\n",
      "episode: 140/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 140.0, score: 499.0\n",
      "episode: 141/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 141.0, score: 499.0\n",
      "episode: 142/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 142.0, score: 499.0\n",
      "episode: 143/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 143.0, score: 499.0\n",
      "episode: 144/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 144.0, score: 499.0\n",
      "episode: 145/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 145.0, score: 499.0\n",
      "episode: 146/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 146.0, score: 499.0\n",
      "episode: 147/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 147.0, score: 499.0\n",
      "episode: 148/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 148.0, score: 499.0\n",
      "episode: 149/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 149.0, score: 499.0\n",
      "episode: 150/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 150.0, score: 499.0\n",
      "episode: 151/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 151.0, score: 499.0\n",
      "episode: 152/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 152.0, score: 499.0\n",
      "episode: 153/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 153.0, score: 499.0\n",
      "episode: 154/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 154.0, score: 499.0\n",
      "episode: 155/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 155.0, score: 499.0\n",
      "episode: 156/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 156.0, score: 499.0\n",
      "episode: 157/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 157.0, score: 499.0\n",
      "episode: 158/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 158.0, score: 499.0\n",
      "episode: 159/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 159.0, score: 499.0\n",
      "episode: 160/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 160.0, score: 499.0\n",
      "episode: 161/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 161.0, score: 499.0\n",
      "episode: 162/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 162.0, score: 499.0\n",
      "episode: 163/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 163.0, score: 499.0\n",
      "episode: 164/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 164.0, score: 499.0\n",
      "episode: 165/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 165.0, score: 499.0\n",
      "episode: 166/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 166.0, score: 499.0\n",
      "episode: 167/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 167.0, score: 499.0\n",
      "episode: 168/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 168.0, score: 499.0\n",
      "episode: 169/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 169.0, score: 499.0\n",
      "episode: 170/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 170.0, score: 499.0\n",
      "episode: 171/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 171.0, score: 499.0\n",
      "episode: 172/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 172.0, score: 499.0\n",
      "episode: 173/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 173.0, score: 499.0\n",
      "episode: 174/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 174.0, score: 499.0\n",
      "episode: 175/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 175.0, score: 499.0\n",
      "episode: 176/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 176.0, score: 499.0\n",
      "episode: 177/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 177.0, score: 499.0\n",
      "episode: 178/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 178.0, score: 499.0\n",
      "episode: 179/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 179.0, score: 499.0\n",
      "episode: 180/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 180.0, score: 499.0\n",
      "episode: 181/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 181.0, score: 499.0\n",
      "episode: 182/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 182.0, score: 499.0\n",
      "episode: 183/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 183.0, score: 499.0\n",
      "episode: 184/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 184.0, score: 499.0\n",
      "episode: 185/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 185.0, score: 499.0\n",
      "episode: 186/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 186.0, score: 499.0\n",
      "episode: 187/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 187.0, score: 499.0\n",
      "episode: 188/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 188.0, score: 499.0\n",
      "episode: 189/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 189.0, score: 499.0\n",
      "episode: 190/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 190.0, score: 499.0\n",
      "episode: 191/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 191.0, score: 499.0\n",
      "episode: 192/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 192.0, score: 499.0\n",
      "episode: 193/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 193.0, score: 499.0\n",
      "episode: 194/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 194.0, score: 499.0\n",
      "episode: 195/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 195.0, score: 499.0\n",
      "episode: 196/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 196.0, score: 499.0\n",
      "episode: 197/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 197.0, score: 499.0\n",
      "episode: 198/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 198.0, score: 499.0\n",
      "episode: 199/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 199.0, score: 499.0\n",
      "episode: 200/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 200.0, score: 499.0\n",
      "episode: 201/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 201.0, score: 499.0\n",
      "episode: 202/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 202.0, score: 499.0\n",
      "episode: 203/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 203.0, score: 499.0\n",
      "episode: 204/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 204.0, score: 499.0\n",
      "episode: 205/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 205.0, score: 499.0\n",
      "episode: 206/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 206.0, score: 499.0\n",
      "episode: 207/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 207.0, score: 499.0\n",
      "episode: 208/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 208.0, score: 499.0\n",
      "episode: 209/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 209.0, score: 499.0\n",
      "episode: 210/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 210.0, score: 499.0\n",
      "episode: 211/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 211.0, score: 499.0\n",
      "episode: 212/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 212.0, score: 499.0\n",
      "episode: 213/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 213.0, score: 499.0\n",
      "episode: 214/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 214.0, score: 499.0\n",
      "episode: 215/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 215.0, score: 499.0\n",
      "episode: 216/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 216.0, score: 499.0\n",
      "episode: 217/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 217.0, score: 499.0\n",
      "episode: 218/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 218.0, score: 499.0\n",
      "episode: 219/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 219.0, score: 499.0\n",
      "episode: 220/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 220.0, score: 499.0\n",
      "episode: 221/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 221.0, score: 499.0\n",
      "episode: 222/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 222.0, score: 499.0\n",
      "episode: 223/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 223.0, score: 499.0\n",
      "episode: 224/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 224.0, score: 499.0\n",
      "episode: 225/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 225.0, score: 499.0\n",
      "episode: 226/300, score: 499, e: 0.0099\n",
      "Best model saved - episode: 226.0, score: 499.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import cartpole_mod\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import json\n",
    "# Version 1.3\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "        self.train_info = []        # for Training accuracy & loss\n",
    "\n",
    "    \"\"\"Huber loss for Q Learning\n",
    "\n",
    "    References: https://en.wikipedia.org/wiki/Huber_loss\n",
    "                https://www.tensorflow.org/api_docs/python/tf/losses/huber_loss\n",
    "    \"\"\"\n",
    "\n",
    "    def _huber_loss(self, y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond  = K.abs(error) <= clip_delta\n",
    "\n",
    "        squared_loss = 0.5 * K.square(error)\n",
    "        quadratic_loss = 0.5 * K.square(clip_delta) + clip_delta * (K.abs(error) - clip_delta)\n",
    "\n",
    "        return K.mean(tf.where(cond, squared_loss, quadratic_loss))\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=self._huber_loss,\n",
    "                      optimizer=Adam(lr=self.learning_rate),\n",
    "                     metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        hist_batch = [] # for training accuracy & loss\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                # a = self.model.predict(next_state)[0]\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "                # target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "            hist = self.model.fit(state, target, epochs=1, verbose=0)\n",
    "            # hist has the length of batch size\n",
    "            # Mean accuracy & loss should be calculated\n",
    "            hist_batch.append([hist.history['acc'], hist.history['loss']])\n",
    "            # self.model.fit(state, target, epochs=1, verbose=0)                 #######필요한지 확인바람\n",
    "        \n",
    "        hist_batch = np.array(hist_batch)\n",
    "        acc_loss = [np.mean(hist_batch[:,0]), np.mean(hist_batch[:,1])]\n",
    "        self.train_info.append(acc_loss)    # Save the training acc & loss\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def get_history(self):       \n",
    "        data = self.train_info\n",
    "        self.train_info = []  # For new episode, it should be cleared\n",
    "        return data\n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "    set_session(tf.Session(config=config))\n",
    "    env = gym.make('CartPole-v3')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    #agent.load(\"./save/cartpole-ddqn.h5\")\n",
    "    done = False\n",
    "    batch_size = 32\n",
    "    \n",
    "    \n",
    "    history = {}\n",
    "    history['score'] = []\n",
    "    history['epsilon'] = []\n",
    "    temp_score = 0\n",
    "    temp_epsilon = 0\n",
    "\n",
    "    \n",
    "    records = np.zeros((1,2))\n",
    "    \n",
    "    trialnumber = \"node_42\"#.format(agent.epsilon) #이부분을 자기가 바꿀것!\n",
    "    \n",
    "    #Make the bestscore file into 1\n",
    "    #i = 1\n",
    "    #f = open(\"./save/cartpole_ddqn_Bestscore_{0}.txt\".format(trialnumber), 'w')\n",
    "    #f.write(\"{}\" .format(i))\n",
    "    #f.close()\n",
    "    \n",
    "    #If bestscore is bigger than 50, epsilon must be 0.1. Only one time\n",
    "    #f = open(\"./save/cartpole_ddqn_Bestscore.txt\", 'r')\n",
    "    #exscore = float(f.readline()) \n",
    "    #f.close()\n",
    "    #if exscore >= 50 :\n",
    "    #    agent.epsilon = 0.1\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        #agent.load(\"./save/cartpole-ddqn.h5\")\n",
    "        #done = False\n",
    "        batch_size = 32\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        temp_epsilon = 0\n",
    "        tmep_score = 0\n",
    "        for time in range(500):\n",
    "            # env.render()\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            reward = reward if not done else -10\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                agent.update_target_model()\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, time, agent.epsilon))\n",
    "                temp_epsilon = agent.epsilon\n",
    "                temp_score = time\n",
    "                if e == 0:\n",
    "                    records[0] = np.array([e, time])\n",
    "                else:\n",
    "                    records = np.concatenate((records, [[e, time]]), axis=0)\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "                \n",
    "        if done is False :\n",
    "            \n",
    "            temp_score = 499\n",
    "            temp_epsilon = agent.epsilon\n",
    "            agent.update_target_model()\n",
    "            records = np.concatenate((records, [[e, temp_score]]), axis=0)\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, temp_score, agent.epsilon))\n",
    "        #Save the ex-bestscore to continue next time        \n",
    "        if records[-1,1] >= np.amax(records[:,1]):\n",
    "            #f = open(\"./save/cartpole_ddqn_Bestscore_{0}.txt\".format(trialnumber), 'r')\n",
    "            #line = float(f.readline())\n",
    "            #f.close()\n",
    "            #if records[-1,1] >= line :\n",
    "            #    f = open(\"./save/cartpole_ddqn_Bestscore_{0}.txt\".format(trialnumber), 'w')\n",
    "            #    f.write(\"{}\" .format(records[-1,1]))\n",
    "            #    f.close()\n",
    "            agent.save(\"./save/cartpole-ddqn_{0}.h5\".format(trialnumber))\n",
    "            print(\"Best model saved - episode: {}, score: {}\".format(records[-1,0], records[-1,1]))\n",
    "        history[e] = agent.get_history()\n",
    "        history['score'].append(temp_score)\n",
    "        history['epsilon'].append(temp_epsilon)\n",
    "    json = json.dumps(history)\n",
    "    f = open(\"./logs/history_{0}.json\".format(trialnumber), 'w')\n",
    "    f.write(json)\n",
    "    f.close()\n",
    "        # if e % 10 == 0:\n",
    "        #     agent.save(\"./save/cartpole-ddqn.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
